{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel(r'Crude model\\2.input\\development dataset.xlsx',sheet_name=\"Sheet 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Halo_Sign'] = data['Halo_Sign'].map({'Exists':1,'Absent':0})  \n",
    "data['Gender'] = data['Gender'].map({'Female':1,'Male':0})\n",
    "data['Composition'] = data['Composition'].map({'Solid':1,'Others':0})\n",
    "data['Shape'] = data['Shape'].map({'Microlobulated':1,'Others':0})\n",
    "data['Echogenicity'] = data['Echogenicity'].map({'Hypoechogenicity':1,'Others':0})\n",
    "data['Echogenic_Foci'] = data['Echogenic_Foci'].map({'Microcalcification':1,'Others':0})\n",
    "data['Margin'] = data['Margin'].map({'Irregular':1,'Smooth':0})\n",
    "data['ATR'] = data['ATR'].map({'Taller_than_Wide':1,'Wider_than_Tall':0})\n",
    "data['Pathological_Diagnosis'] = data['Pathological_Diagnosis'].map({'Malignant':1,'Benign':0})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded1 = pd.get_dummies(data, columns=['Posterior_Echo'], prefix='')\n",
    "df_encoded1.rename(columns={'_Absent_of_Shadowing':'Absent_of_Shadowing','_Posterior_Attenuation':'Posterior_Attenuation','_Shadowing':'Shadowing'},inplace=True)\n",
    "columns_to_convert1 = ['Absent_of_Shadowing','Posterior_Attenuation','Shadowing']\n",
    "df_encoded1[columns_to_convert1] = df_encoded1[columns_to_convert1].astype(int)\n",
    "\n",
    "df_encoded2 = pd.get_dummies(df_encoded1, columns=['Location'], prefix='')\n",
    "df_encoded2.rename(columns={'_Right_Lobe':'Right_Lobe','_Left_Lobe':'Left_Lobe','_Isthmus':'Isthmus'},inplace=True)\n",
    "columns_to_convert2 = ['Right_Lobe','Left_Lobe','Isthmus']\n",
    "df_encoded2[columns_to_convert2] = df_encoded2[columns_to_convert2].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "order_list = ['Intra_BFS','Peri_BFS']\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for i in order_list:\n",
    "    \n",
    "    df_encoded2[i] = label_encoder.fit_transform(df_encoded2[i])\n",
    "\n",
    "    for class_label, encoded_label in zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)):\n",
    "        print(f\"{class_label}: {encoded_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_input_reconde = df_encoded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pycaret.classification import *\n",
    "exp_clf = setup(\n",
    "    data_input_reconde, target='Pathological_Diagnosis', session_id=111,\n",
    "    numeric_features=[\"BMI\",\"Age\",\"Maximum_Diameter\"],\n",
    "    categorical_features=[\"Halo_Sign\", \n",
    "    \"Gender\",\"Composition\",\"Shape\",\"Echogenicity\",\"Echogenic_Foci\",\n",
    "    \"Margin\",\"ATR\",\"Absent_of_Shadowing\",\"Posterior_Attenuation\",\"Shadowing\",\n",
    "    \"Right_Lobe\",\"Left_Lobe\",\"Isthmus\"], \n",
    "    train_size = 0.7,data_split_shuffle = True,data_split_stratify = True,\n",
    "    ignore_features=[\"ACR\",\"Kwak\",\"Data_Type\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_transformed = get_config(\"X_train_transformed\")\n",
    "y_train_transformed = get_config(\"y_train_transformed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pycaret\n",
    "\n",
    "input_dir = r\"\" #Model_pkl path \n",
    "model_params_dict = {}\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "\n",
    "        model_name = file.split(\".pkl\")[0]\n",
    "        file_path = os.path.join(root, model_name)\n",
    "        model_init = load_model(file_path)\n",
    "        \n",
    "        parm = model_init[-1].get_params()\n",
    "\n",
    "        model_params_dict[model_name] = parm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "def create_models_with_optimized_hyperparameters(optimized_params_dict):\n",
    "\n",
    "    models_name_model = {}\n",
    "    \n",
    "    # 1. CatBoost Classifier\n",
    "    catboost_params = optimized_params_dict['CatBoost Classifier']\n",
    "    models_name_model['CatBoost Classifier'] = CatBoostClassifier(**catboost_params)\n",
    "    \n",
    "    # 2. Gradient Boosting Classifier\n",
    "    gbc_params = optimized_params_dict['Gradient Boosting Classifier']\n",
    "    models_name_model['Gradient Boosting Classifier'] = GradientBoostingClassifier(**gbc_params)\n",
    "    \n",
    "    # 3. Extreme Gradient Boosting (XGBoost)\n",
    "    xgb_params = optimized_params_dict['Extreme Gradient Boosting']\n",
    "    models_name_model['Extreme Gradient Boosting'] = XGBClassifier(**xgb_params)\n",
    "    \n",
    "    # 4. Light Gradient Boosting Machine\n",
    "    lgbm_params = optimized_params_dict['Light Gradient Boosting Machine']\n",
    "    models_name_model['Light Gradient Boosting Machine'] = LGBMClassifier(**lgbm_params)\n",
    "    \n",
    "    # 5. Neural Network (MLP Classifier)\n",
    "    mlp_params = optimized_params_dict['MLP Classifier']\n",
    "    models_name_model['MLP Classifier'] = MLPClassifier(**mlp_params)\n",
    "    \n",
    "    # 6. Random Forest Classifier\n",
    "    rf_params = optimized_params_dict['Random Forest Classifier']\n",
    "    models_name_model['Random Forest Classifier'] = RandomForestClassifier(**rf_params)\n",
    "    \n",
    "    # 7. Extra Trees Classifier\n",
    "    et_params = optimized_params_dict['Extra Trees Classifier']\n",
    "    models_name_model['Extra Trees Classifier'] = ExtraTreesClassifier(**et_params)\n",
    "    \n",
    "    # 8. Adaptive Boosting Classifier\n",
    "    ada_params = optimized_params_dict['Ada Boost Classifier']\n",
    "    models_name_model['Ada Boost Classifier'] = AdaBoostClassifier(**ada_params)\n",
    "    \n",
    "    # 9. Logistic Regression\n",
    "    lr_params = optimized_params_dict['Logistic Regression']\n",
    "    models_name_model['Logistic Regression'] = LogisticRegression(**lr_params)\n",
    "    \n",
    "    # 10. Ridge Classifier\n",
    "    ridge_params = optimized_params_dict['Ridge Classifier']\n",
    "    models_name_model['Ridge Classifier'] = RidgeClassifier(**ridge_params)\n",
    "    \n",
    "    # 11. Linear Discriminant Analysis\n",
    "    lda_params = optimized_params_dict['Linear Discriminant Analysis']\n",
    "    models_name_model['Linear Discriminant Analysis'] = LinearDiscriminantAnalysis(**lda_params)\n",
    "    \n",
    "    # 12. Quadratic Discriminant Analysis\n",
    "    qda_params = optimized_params_dict['Quadratic Discriminant Analysis']\n",
    "    models_name_model['Quadratic Discriminant Analysis'] = QuadraticDiscriminantAnalysis(**qda_params)\n",
    "    \n",
    "    # 13. Decision Tree Classifier\n",
    "    dt_params = optimized_params_dict['Decision Tree Classifier']\n",
    "    models_name_model['Decision Tree Classifier'] = DecisionTreeClassifier(**dt_params)\n",
    "    \n",
    "    # 14. Naive Bayes\n",
    "    nb_params = optimized_params_dict['Naive Bayes']    \n",
    "    models_name_model['Naive Bayes'] = GaussianNB(**nb_params)\n",
    "    \n",
    "    # 15. K-Nearest Neighbor Classifier\n",
    "    knn_params = optimized_params_dict['K Neighbors Classifier']\n",
    "    models_name_model['K Neighbors Classifier'] = KNeighborsClassifier(**knn_params)\n",
    "    \n",
    "    # 16. Support Vector Machine\n",
    "    svm_params = optimized_params_dict['SVM - Radial Kernel']\n",
    "    models_name_model['SVM - Radial Kernel'] = SVC(**svm_params)\n",
    "    \n",
    "    # 17. Gaussian Process Classifier\n",
    "    gpc_params = optimized_params_dict['Gaussian Process Classifier']   \n",
    "    models_name_model['Gaussian Process Classifier'] = GaussianProcessClassifier(**gpc_params)\n",
    "    \n",
    "    return models_name_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name_model = create_models_with_optimized_hyperparameters(model_params_dict)\n",
    "models_name_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "def feature_selection_with_cv(X_train, y_train, selected_features, models_name_model, cv_folds=10):\n",
    "    \n",
    "    mean_results = []\n",
    "    std_results = []\n",
    "    cv_results = {}\n",
    "   \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    for model_name in models_name_model.keys():\n",
    "        cv_results[model_name] = {\n",
    "            'mean_auc': [],\n",
    "            'std_auc': [],\n",
    "            'all_cv_scores': []  \n",
    "        }\n",
    "    \n",
    "    for num_features in range(1, len(selected_features) + 1):\n",
    "\n",
    "        i = 1\n",
    "        \n",
    "        mean_row = {\"Number_of_Features\": num_features}\n",
    "        std_row = {\"Number_of_Features\": num_features}\n",
    "        \n",
    "        top_features = selected_features[:num_features]\n",
    "        X_train_subset = X_train[top_features]\n",
    "        \n",
    "        for model_name, model_config in models_name_model.items():\n",
    "            try:\n",
    "               \n",
    "                model = clone(model_config)\n",
    "                                \n",
    "                cv_scores = cross_val_score(\n",
    "                    model, X_train_subset, y_train,\n",
    "                    cv=cv, scoring='roc_auc', n_jobs=-1\n",
    "                )\n",
    "                \n",
    "                mean_auc = np.mean(cv_scores)\n",
    "                std_auc = np.std(cv_scores)\n",
    "                \n",
    "                mean_row[model_name] = mean_auc\n",
    "                \n",
    "                std_row[model_name] = std_auc\n",
    "                \n",
    "                cv_results[model_name]['mean_auc'].append(mean_auc)\n",
    "                cv_results[model_name]['std_auc'].append(std_auc)\n",
    "                cv_results[model_name]['all_cv_scores'].append(cv_scores)\n",
    "                \n",
    "            except Exception as e:\n",
    "                mean_row[model_name] = np.nan\n",
    "                std_row[model_name] = np.nan\n",
    "\n",
    "            i = i + 1\n",
    "        mean_results.append(mean_row)\n",
    "        std_results.append(std_row)\n",
    "    \n",
    "    mean_results_df = pd.DataFrame(mean_results)\n",
    "    std_results_df = pd.DataFrame(std_results)\n",
    "\n",
    "    \n",
    "    return mean_results_df, std_results_df, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.base import clone\n",
    "\n",
    "def feature_selection_with_cv_dict(X_train, y_train, shap_feature_importances, models_name_model, cv_folds=10):\n",
    "    \n",
    "    mean_results = []\n",
    "    std_results = []\n",
    "    cv_results = {}\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    for model_name in models_name_model.keys():\n",
    "        cv_results[model_name] = {\n",
    "            'mean_auc': [],\n",
    "            'std_auc': [],\n",
    "            'all_cv_scores': []  \n",
    "        }\n",
    "    \n",
    "    max_features = min(len(features) for features in shap_feature_importances.values())\n",
    "    \n",
    "\n",
    "    for num_features in range(1, max_features + 1):\n",
    "        \n",
    "        i = 1\n",
    "        \n",
    "        mean_row = {\"Number_of_Features\": num_features}\n",
    "        std_row = {\"Number_of_Features\": num_features}\n",
    "        \n",
    "        for model_name, model_config in models_name_model.items():\n",
    "            \n",
    "            selected_features = shap_feature_importances[model_name]\n",
    "            \n",
    "            top_features = selected_features[:num_features]\n",
    "            X_train_subset = X_train[top_features]\n",
    "            \n",
    "            try:\n",
    "                model = clone(model_config)\n",
    "                \n",
    "                cv_scores = cross_val_score(\n",
    "                    model, X_train_subset, y_train,\n",
    "                    cv=cv, scoring='roc_auc', n_jobs=-1\n",
    "                )\n",
    "                \n",
    "                mean_auc = np.mean(cv_scores)\n",
    "                std_auc = np.std(cv_scores)\n",
    "                \n",
    "                mean_row[model_name] = mean_auc\n",
    "                std_row[model_name] = std_auc\n",
    "                \n",
    "                cv_results[model_name]['mean_auc'].append(mean_auc)\n",
    "                cv_results[model_name]['std_auc'].append(std_auc)\n",
    "                cv_results[model_name]['all_cv_scores'].append(cv_scores)\n",
    "               \n",
    "            except Exception as e:\n",
    "                mean_row[model_name] = np.nan\n",
    "                std_row[model_name] = np.nan\n",
    "\n",
    "            i = i + 1\n",
    "            \n",
    "        mean_results.append(mean_row)\n",
    "        std_results.append(std_row)\n",
    "    \n",
    "    mean_results_df = pd.DataFrame(mean_results)\n",
    "    std_results_df = pd.DataFrame(std_results)\n",
    "    \n",
    "    return mean_results_df, std_results_df, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_config(\"X_train_transformed\")\n",
    "y_train = get_config(\"y_train_transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X_train, y_train], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pymrmr\n",
    "target = df.columns[-1]\n",
    "df_reordered = df[[target] + [col for col in df.columns if col != target]]\n",
    "\n",
    "k = 19\n",
    "selected_features = pymrmr.mRMR(df_reordered, 'MIQ', k)\n",
    "\n",
    "\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mRMR_feature_importances_df = pd.DataFrame(selected_features)\n",
    "mRMR_feature_importances_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_results_df, std_results_df, cv_results =  feature_selection_with_cv(X_train, y_train, selected_features, models_name_model, cv_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "step_size = 1  \n",
    "initial_value = 1  \n",
    "\n",
    "\n",
    "filtered_results_df = mean_results_df[\n",
    "    mean_results_df[\"Number_of_Features\"] >= initial_value  \n",
    "].iloc[::step_size, :].reset_index(drop=True)  \n",
    "\n",
    "\n",
    "filtered_results_df.sort_values(by=\"Number_of_Features\", ascending=False, inplace=True)\n",
    "lancet_colors = [\n",
    "    '#00468B', '#ED0000', '#42B540', '#0099B4', '#925E9F', '#FDAF91', '#AD002A', \n",
    "    '#ADB6B6', '#1B1919', '#7C7C7C', '#4DBBD5', '#E64B35', '#00A087', '#3C5488', \n",
    "    '#F39B7F', '#8491B4'\n",
    "]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))  \n",
    "for i, column in enumerate(filtered_results_df.columns[1:]):\n",
    "    plt.plot(\n",
    "        filtered_results_df[\"Number_of_Features\"],  \n",
    "        filtered_results_df[column],              \n",
    "        label=column,                              \n",
    "        color=lancet_colors[i % len(lancet_colors)], \n",
    "        marker='o',                                \n",
    "        linewidth=1.5                              \n",
    "    )\n",
    "\n",
    "\n",
    "optimal_features = 9  \n",
    "plt.axvline(\n",
    "    x=optimal_features,  \n",
    "    color='black',       \n",
    "    linestyle='--',      \n",
    "    label='Optimal Features',  \n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "\n",
    "plt.title('Recursive Feature Elimination', fontsize=10)  \n",
    "plt.xlabel('Number of Features', fontsize=10) \n",
    "plt.ylabel('Area Under the ROC Curve (AUC)', fontsize=10)  \n",
    "\n",
    "plt.xticks(\n",
    "    ticks=filtered_results_df[\"Number_of_Features\"],  \n",
    "    fontsize=8  \n",
    ")\n",
    "plt.yticks(fontsize=8)  \n",
    "plt.legend(title=\"Models\", fontsize=8, loc=\"best\")  \n",
    "plt.grid(axis='y', alpha=0.5)  \n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "# plt.savefig(r'mRMR-ROC.pdf', format='pdf', bbox_inches='tight', dpi=1200)\n",
    "# plt.savefig(r'mRMR-ROC.svg', format='svg', bbox_inches='tight', dpi=1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_config(\"X_train_transformed\")\n",
    "y_train = get_config(\"y_train_transformed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "def boruta_random_forest_feature_selection(X_train, y_train, \n",
    "                                         n_estimators=100, \n",
    "                                         max_iter=100, \n",
    "                                         random_state=42):\n",
    "    \n",
    "    rf = RandomForestClassifier(\n",
    "        class_weight='balanced', \n",
    "        max_depth=5,\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    boruta_selector = BorutaPy(\n",
    "        estimator=rf,\n",
    "        n_estimators='auto',  \n",
    "        max_iter=max_iter,\n",
    "        random_state=random_state,\n",
    "        verbose=0  \n",
    "    )\n",
    "    \n",
    "    boruta_selector.fit(X_train.values, y_train.values)\n",
    "    \n",
    "    feature_ranking = boruta_selector.ranking_\n",
    "    \n",
    "    feature_rank_pairs = list(zip(X_train.columns, feature_ranking))\n",
    "    feature_rank_pairs.sort(key=lambda x: x[1])  \n",
    "    sorted_features = [feature for feature, rank in feature_rank_pairs]\n",
    "    \n",
    "    feature_states = {}\n",
    "    for i, feature in enumerate(X_train.columns):\n",
    "        if boruta_selector.support_[i]:\n",
    "            feature_states[feature] = 'Accepted'\n",
    "        elif hasattr(boruta_selector, 'support_weak_') and boruta_selector.support_weak_[i]:\n",
    "            feature_states[feature] = 'Tentative'\n",
    "        else:\n",
    "            feature_states[feature] = 'Rejected'\n",
    "    \n",
    "    \n",
    "    return sorted_features, feature_states, boruta_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_features, feature_states, boruta_selector = boruta_random_forest_feature_selection(X_train, y_train, n_estimators=100, max_iter=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Boruta_feature = pd.DataFrame([\n",
    "    {'Feature_Name': feature, 'State': status}\n",
    "    for feature, status in feature_states.items()\n",
    "])\n",
    "\n",
    "\n",
    "Boruta_feature['State'] = pd.Categorical(Boruta_feature['State'], \n",
    "                            categories=['Accepted', 'Tentative', 'Rejected'], \n",
    "                            ordered=True)\n",
    "Boruta_feature_sorted = Boruta_feature.sort_values('State').reset_index(drop=True)\n",
    "Boruta_feature_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boruta_feature_list = Boruta_feature_sorted['Feature_Name'].to_list()\n",
    "Boruta_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_results_df, std_results_df, cv_results = feature_selection_with_cv(X_train, y_train, Boruta_feature_list, models_name_model, cv_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "step_size = 1  \n",
    "initial_value = 1  \n",
    "\n",
    "\n",
    "filtered_results_df = mean_results_df[\n",
    "    mean_results_df[\"Number_of_Features\"] >= initial_value  \n",
    "].iloc[::step_size, :].reset_index(drop=True)  \n",
    "\n",
    "\n",
    "filtered_results_df.sort_values(by=\"Number_of_Features\", ascending=False, inplace=True)\n",
    "lancet_colors = [\n",
    "    '#00468B', '#ED0000', '#42B540', '#0099B4', '#925E9F', '#FDAF91', '#AD002A', \n",
    "    '#ADB6B6', '#1B1919', '#7C7C7C', '#4DBBD5', '#E64B35', '#00A087', '#3C5488', \n",
    "    '#F39B7F', '#8491B4'\n",
    "]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))  \n",
    "for i, column in enumerate(filtered_results_df.columns[1:]):\n",
    "    plt.plot(\n",
    "        filtered_results_df[\"Number_of_Features\"],  \n",
    "        filtered_results_df[column],               \n",
    "        label=column,                             \n",
    "        color=lancet_colors[i % len(lancet_colors)], \n",
    "        marker='o',                               \n",
    "        linewidth=1.5                             \n",
    "    )\n",
    "\n",
    "\n",
    "optimal_features = 10  \n",
    "plt.axvline(\n",
    "    x=optimal_features,  \n",
    "    color='black',       \n",
    "    linestyle='--',      \n",
    "    label='Optimal Features',  \n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "\n",
    "plt.title('Recursive Feature Elimination', fontsize=10)  \n",
    "plt.xlabel('Number of Features', fontsize=10)  \n",
    "plt.ylabel('Area Under the ROC Curve (AUC)', fontsize=10)  \n",
    "plt.xticks(\n",
    "    ticks=filtered_results_df[\"Number_of_Features\"],  \n",
    "    fontsize=8  \n",
    ")\n",
    "plt.yticks(fontsize=8)  \n",
    "plt.legend(title=\"Models\", fontsize=8, loc=\"best\")  \n",
    "plt.grid(axis='y', alpha=0.5)  \n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "# plt.savefig(r'Boruta-ROC.pdf', format='pdf', bbox_inches='tight', dpi=1200)\n",
    "# plt.savefig(r'Boruta-ROC.svg', format='svg', bbox_inches='tight', dpi=1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BorutaShap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from BorutaShap import BorutaShap\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_config(\"X_train_transformed\")\n",
    "y_train = get_config(\"y_train_transformed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced',max_depth=5,n_estimators=100,random_state=42,n_jobs=-1)\n",
    "\n",
    "Feature_Selector = BorutaShap(model=rf, importance_measure='shap', classification=True)\n",
    "Feature_Selector.fit(X=X_train, y=y_train, n_trials=100, sample=False, train_or_test='train', normalize=True, verbose=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_Selector.plot(y_scale='log', which_features='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_boruta_features(accepted_features, tentative_features, rejected_features):\n",
    "    \n",
    "    features_data = []\n",
    "    \n",
    "\n",
    "    for feature in accepted_features:\n",
    "        features_data.append({'Feature_Name': feature, 'Status': 'Accepted'})\n",
    "    \n",
    "    for feature in tentative_features:\n",
    "        features_data.append({'Feature_Name': feature, 'Status': 'Tentative'})\n",
    "    \n",
    "    for feature in rejected_features:\n",
    "        features_data.append({'Feature_Name': feature, 'Status': 'Rejected'})\n",
    "    \n",
    "    features_df = pd.DataFrame(features_data)\n",
    "    \n",
    "    all_features_list = accepted_features + tentative_features + rejected_features\n",
    "    \n",
    "    return features_df, all_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS_features_df, BS_features_list = process_boruta_features(Feature_Selector.accepted, Feature_Selector.tentative, Feature_Selector.rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_results_df_BS, std_results_df_BS, cv_results_BS =  feature_selection_with_cv(X_train, y_train, BS_features_list, models_name_model, cv_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "\n",
    "step_size = 1  \n",
    "initial_value = 1  \n",
    "\n",
    "\n",
    "filtered_results_df = mean_results_df_BS[\n",
    "    mean_results_df_BS[\"Number_of_Features\"] >= initial_value  \n",
    "].iloc[::step_size, :].reset_index(drop=True)  \n",
    "\n",
    "\n",
    "filtered_results_df.sort_values(by=\"Number_of_Features\", ascending=False, inplace=True)\n",
    "\n",
    "lancet_colors = [\n",
    "    '#00468B', '#ED0000', '#42B540', '#0099B4', '#925E9F', '#FDAF91', '#AD002A', \n",
    "    '#ADB6B6', '#1B1919', '#7C7C7C', '#4DBBD5', '#E64B35', '#00A087', '#3C5488', \n",
    "    '#F39B7F', '#8491B4'\n",
    "]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))  \n",
    "for i, column in enumerate(filtered_results_df.columns[1:]):\n",
    "    plt.plot(\n",
    "        filtered_results_df[\"Number_of_Features\"],  \n",
    "        filtered_results_df[column],               \n",
    "        label=column,                              \n",
    "        color=lancet_colors[i % len(lancet_colors)], \n",
    "        marker='o',                                \n",
    "    )\n",
    "\n",
    "optimal_features = 12  \n",
    "plt.axvline(\n",
    "    x=optimal_features,  \n",
    "    color='black',       \n",
    "    linestyle='--',      \n",
    "    label='Optimal Features',  \n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "\n",
    "plt.title('Recursive Feature Elimination', fontsize=10)  \n",
    "plt.xlabel('Number of Features', fontsize=10)  \n",
    "plt.ylabel('Area Under the ROC Curve (AUC)', fontsize=10)  \n",
    "plt.xticks(\n",
    "    ticks=filtered_results_df[\"Number_of_Features\"], \n",
    "    fontsize=8  \n",
    ")\n",
    "plt.yticks(fontsize=8) \n",
    "plt.legend(title=\"Models\", fontsize=8, loc=\"best\") \n",
    "plt.grid(axis='y', alpha=0.5) \n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "# plt.savefig(r'BorutaShap-ROC.pdf', format='pdf', bbox_inches='tight', dpi=1200)\n",
    "# plt.savefig(r'BorutaShap-ROC.svg', format='svg', bbox_inches='tight', dpi=1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_config(\"X_train_transformed\")\n",
    "y_train = get_config(\"y_train_transformed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_names = X_train.columns\n",
    "\n",
    "alphas = np.logspace(-4, 4, 1000)  \n",
    "\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=RepeatedKFold(n_splits=10, n_repeats=10, random_state=42), random_state=42,max_iter=100,n_jobs=-1)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "mse_path = lasso_cv.mse_path_.mean(axis=1)  \n",
    "mse_std = lasso_cv.mse_path_.std(axis=1)    \n",
    "\n",
    "best_alpha_index = np.argmin(mse_path)  \n",
    "best_alpha = lasso_cv.alphas_[best_alpha_index] \n",
    "\n",
    "print(f\"Best alpha (λ_min): {best_alpha}\")\n",
    "\n",
    "\n",
    "lasso_best_alpha = LassoCV(alphas=[best_alpha], cv=RepeatedKFold(n_splits=10, n_repeats=10, random_state=42), random_state=42,max_iter=100,n_jobs=-1)\n",
    "lasso_best_alpha.fit(X_train_scaled, y_train)\n",
    "selected_features_best = [feature_names[i] for i in np.where(lasso_best_alpha.coef_ != 0)[0]]  \n",
    "print(f\"Selected features with λ_min: {selected_features_best}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a, max_iter=10000)\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.xscale('log')  \n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "plt.axvline(lasso_cv.alphas_[best_alpha_index], linestyle='--', color='black', label=r'$\\lambda_{min}$='+str(round(best_alpha, 4)))\n",
    "\n",
    "plt.xlabel('Alpha (α) value', fontsize=10)\n",
    "plt.ylabel('Coefficients', fontsize=10)\n",
    "plt.title('Lasso Paths', fontsize=10)\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "\n",
    "# plt.savefig(r'Lasso.pdf', format='pdf', bbox_inches='tight', dpi=1200)\n",
    "# plt.savefig(r'Lasso.svg', format='svg', bbox_inches='tight', dpi=1200)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = get_config(\"X_train_transformed\")\n",
    "y_train = get_config(\"y_train_transformed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "elastic_net = ElasticNetCV(l1_ratio=np.linspace(0.01, 1, 100),  \n",
    "                           alphas=np.logspace(-4, 4, 100),\n",
    "                           cv=10,\n",
    "                           max_iter=100,  \n",
    "                           random_state=42)\n",
    "elastic_net.fit(X_train_scaled, y_train)\n",
    "print(\"Best alpha:\", elastic_net.alpha_)\n",
    "print(\"Best l1_ratio:\", elastic_net.l1_ratio_)\n",
    "feature_coef = elastic_net.coef_\n",
    "selected_features = X_train.columns[feature_coef != 0].tolist()\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "coefs = []\n",
    "for alpha in alphas:\n",
    "    elastic_net_1 = ElasticNet(alpha=alpha, l1_ratio=elastic_net.l1_ratio_, max_iter=100)  \n",
    "    elastic_net_1.fit(X_train_scaled, y_train)\n",
    "    coefs.append(elastic_net_1.coef_)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.xscale('log')  \n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "plt.axvline(elastic_net.alpha_ , linestyle='--', color='black', label=r'$\\lambda_{min}$='+str(round(best_alpha, 4)))\n",
    "plt.xlabel('Alpha (α) value', fontsize=10)\n",
    "plt.ylabel('Coefficients', fontsize=10)\n",
    "plt.title('Coefficient Path Using ElasticNet with Best L1 ratio', fontsize=10)\n",
    "plt.axis('tight')\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.legend(fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "# plt.savefig(r'ElasticNet.pdf', format='pdf', bbox_inches='tight', dpi=1200)\n",
    "# plt.savefig(r'ElasticNet.svg', format='svg', bbox_inches='tight', dpi=1200)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thyroid_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
